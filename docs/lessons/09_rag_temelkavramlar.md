### RAG Nedir?
Retrieval-Augmented Generation (RAG), bÃ¼yÃ¼k dil modellerinin (LLM) dÄ±ÅŸ bilgi kaynaklarÄ±nÄ± kullanarak metin Ã¼retmesini saÄŸlayan bir yapay zeka mimarisidir. KÄ±saca, bir LLMâ€™e entegre edilen bilgi getirme (retrieval) mekanizmasÄ± sayesinde model, yanÄ±t Ã¼retirken eÄŸitim verilerinin Ã¶tesindeki gÃ¼ncel ve gÃ¼venilir bilgilere eriÅŸebilir. Bu teknik ile model Ã§Ä±ktÄ±larÄ± kanÄ±tlara dayalÄ± hale gelir ve daha isabetli olur. RAG yaklaÅŸÄ±mÄ±, doÄŸal dil iÅŸleme alanÄ±nda bilgi Ã§ekme (retrieval) ve metin Ã¼retimi (generation) yeteneklerini tek bir Ã§atÄ± altÄ±nda birleÅŸtirir; bÃ¶ylece modeller daha derin ve bilgi odaklÄ± cevaplar Ã¼retebilir.

### Neden Ã–nemlidir?
Geleneksel bÃ¼yÃ¼k dil modelleri eÄŸitim aldÄ±klarÄ± veriyle sÄ±nÄ±rlÄ±dÄ±r ve zamanla bilgilerinin gÃ¼ncelliÄŸini yitirir. Bu modeller, parametrelerine â€œgÃ¶mÃ¼lÃ¼â€ olmayan yeni bilgiler karÅŸÄ±sÄ±nda halÃ¼sinasyon diyebileceÄŸimiz uydurma cevaplar verebilir. RAG, LLMâ€™lerin gÃ¼ncel ve doÄŸrulanabilir bilgiye eriÅŸimini saÄŸlayarak bu sorunlarÄ± giderir. Temel modeli yeniden eÄŸitmeye gerek kalmadan, modele harici veri kaynaklarÄ±ndan hedeflenmiÅŸ bilgiler sunulur; model de bu sayede baÄŸlama uygun, tutarlÄ± ve gÃ¼ncel yanÄ±tlar oluÅŸturabilir. SonuÃ§ olarak RAG, LLMâ€™lerin tek baÅŸÄ±na yapabildiklerinin Ã¶tesine geÃ§ip yanÄ±t kalitesini artÄ±rÄ±r ve hatalÄ± Ã§Ä±karÄ±mlarÄ± azaltÄ±r. AyrÄ±ca, RAG yaklaÅŸÄ±mÄ± sayesinde bir modelin bilgi tabanÄ± istenildiÄŸi zaman gÃ¼ncellenebildiÄŸinden, modeli yeniden eÄŸitmenin yÃ¼ksek maliyetinden kaÃ§Ä±nÄ±lÄ±r.

### KullanÄ±m AlanlarÄ±
RAG mimarisi, geniÅŸ bir uygulama yelpazesinde kullanÄ±lÄ±r. AÅŸaÄŸÄ±da bazÄ± Ã¶nemli kullanÄ±m alanlarÄ± yer almaktadÄ±r:

- **Soru-Cevap ve Arama MotorlarÄ±:** RAG, arama motorlarÄ± ve aÃ§Ä±k uÃ§lu soru-cevap sistemlerinde gÃ¼ncel bilgiye dayalÄ± cevaplar vermek iÃ§in idealdir. Ã–rneÄŸin, Bing gibi modern arama asistanlarÄ±, webâ€™den ilgili iÃ§erikleri getirip dil modeli ile cevabÄ± derleyerek kullanÄ±cÄ±lara sunar.
- **MÃ¼ÅŸteri DesteÄŸi ChatbotlarÄ±:** Åirketler, Ã¼rÃ¼n ve hizmet bilgilerini iÃ§eren bilgi tabanlarÄ±nÄ± LLMâ€™lere entegre ederek mÃ¼ÅŸteri sorularÄ±na doÄŸru yanÄ±tlar verir. OpenAIâ€™nin ChatGPT modelinin knowledge retrieval Ã¶zelliÄŸi ile destek ekibi botlarÄ±nÄ±n, geÃ§miÅŸ destek kayÄ±tlarÄ±nÄ± sorgulayÄ±p gÃ¼ncel ve ÅŸirket-Ã¶zel cevaplar Ã¼retmesi buna Ã¶rnek verilebilir.
- **KiÅŸisel Asistanlar:** KiÅŸisel dokÃ¼manlar, e-postalar veya notlar Ã¼zerinde Ã§alÄ±ÅŸan yapay zeka asistanlarÄ± RAGâ€™den faydalanÄ±r. Ã–rneÄŸin, Notionâ€™Ä±n Ask AI Ã¶zelliÄŸi ya da Microsoftâ€™un Copilot sistemi, kullanÄ±cÄ±nÄ±n kendi verilerinden arama yaparak sorularÄ± yanÄ±tlar ve belge Ã¶zetleme gibi iÅŸlemleri gerÃ§ekleÅŸtirir.
- **Ä°Ã§erik Ã–neri Sistemleri:** RAG, geleneksel olarak karmaÅŸÄ±k model kombinasyonlarÄ± gerektiren iÃ§erik tavsiye problemlerini basitleÅŸtirebilir. Bir LLMâ€™in genel bilgisini, kullanÄ±cÄ±nÄ±n Ã¶zel tercih verileriyle birleÅŸtirerek kiÅŸiselleÅŸtirilmiÅŸ Ã¶neriler oluÅŸturmak mÃ¼mkÃ¼ndÃ¼r.
- **Kurumsal Bilgi YÃ¶netimi:** Kurum iÃ§i dokÃ¼man arama, hukuki dokÃ¼man analizi, tÄ±bbi literatÃ¼r taramasÄ± gibi alanlarda RAG kullanÄ±mÄ± yaygÄ±ndÄ±r. Ã–rneÄŸin, bir saÄŸlÄ±k araÅŸtÄ±rma asistanÄ± RAG modeli, bir tÄ±bbi veritabanÄ±ndan ilgili makaleleri getirip doktorun sorduÄŸu soruya dayalÄ± derlenmiÅŸ bir cevap verebilir.

## Temel Kavramlar

### Bilgi Getirme (Retrieval) Nedir?
Bilgi getirme, bir kullanÄ±cÄ± sorgusuna yanÄ±t olarak bÃ¼yÃ¼k bir veri koleksiyonundan ilgili bilgi parÃ§alarÄ±nÄ± bulma iÅŸlemidir. BaÅŸka bir deyiÅŸle, doÄŸru bilgiyi arama problemidir. Bu kapsamda bilgi getirme sistemleri, sorgudaki anahtar kelime ve kavramlara gÃ¶re dokÃ¼manlarÄ± tarar ve en alakalÄ± sonuÃ§larÄ± geri dÃ¶ndÃ¼rÃ¼râ€‹. Ã–rneÄŸin bir arama motoru, kullanÄ±cÄ±nÄ±n girdiÄŸi sorguya uygun web sayfalarÄ±nÄ± listelerken bilgi getirme tekniklerini kullanÄ±r. RAG baÄŸlamÄ±nda, LLMâ€™e entegre edilen bilgi getirme modÃ¼lÃ¼, modelin parametrelerinde yer almayan harici bilgileri bulup modelin kullanÄ±mÄ±na sunar.

### Metin Ãœretme (Generation) SÃ¼reci NasÄ±l Ä°ÅŸler?
Metin Ã¼retimi, bir yapay zeka modelinin verilen girdiye dayanarak yeni ve anlamlÄ± doÄŸal dil metni oluÅŸturma sÃ¼recidir. Bu sÃ¼reÃ§te model, dil bilgisini ve istatistiksel Ã¶rÃ¼ntÃ¼leri kullanarak birer birer kelimeler veya cÃ¼mleler Ã¼retirâ€‹. Genellikle metin Ã¼retimi yapan dil modelleri, bir baÅŸlangÄ±Ã§ prompt (tetikleyici metin) alÄ±r ve olasÄ±lÄ±ksal olarak sÄ±radaki kelimeyi tahmin ederek Ã§Ä±ktÄ±yÄ± geniÅŸletir. Bu dÃ¶ngÃ¼, istenen uzunluÄŸa ulaÅŸana dek veya model bir bitiÅŸ belirtecine ulaÅŸana kadar devam eder. Ã–rneÄŸin, â€œBir kedi ve kÃ¶pekâ€¦â€ ÅŸeklinde baÅŸlayan bir cÃ¼mleyi tamamlamasÄ± istendiÄŸinde, model eÄŸitim sÄ±rasÄ±nda Ã¶ÄŸrendiÄŸi dil kalÄ±plarÄ±na dayanarak muhtemel devamÄ± yazar. Ã–nemli olan, Ã¼retilen metnin dilbilgisel aÃ§Ä±dan doÄŸru, tutarlÄ± ve verilen baÄŸlama uygun olmasÄ±dÄ±r. Ã–rneÄŸin, kurumsal bir RAG modeli kendi ÅŸirketinizin iÃ§ dokÃ¼manlarÄ±nÄ± kullanarak sorularÄ± yanÄ±tlayabilir, oysa genel bir LLM bunu bilemez.
### RAGâ€™Ä±n Klasik Ãœretken Modellere GÃ¶re FarklarÄ±
- **GÃ¼ncel ve Dinamik Bilgi:** AG, modelin eÄŸitim verilerinden daha taze olabilecek bilgilere eriÅŸim saÄŸlar. LLMâ€™nin eÄŸitildiÄŸi veri zamanla eskiyebilir; oysa RAG modeli, harici bilgi kaynaÄŸÄ± sÃ¼rekli gÃ¼ncellenebildiÄŸi iÃ§in her zaman gÃ¼ncel veriyi kullanabilirâ€‹.
- **BaÄŸlamsal DoÄŸruluk ve Ã–zelleÅŸtirme:** Klasik modeller genelleÅŸtirilmiÅŸ bilgi sunarken, RAG sistemine entegre edilen bilgi havuzu daha baÄŸlama Ã¶zgÃ¼ veriler iÃ§erebilir. Bu sayede model, belirli bir sektÃ¶r veya kuruluÅŸa ait Ã¶zel bilgileri dahi yanÄ±tlarÄ±na yansÄ±tabilirâ€‹. 
- **AzaltÄ±lmÄ±ÅŸ HalÃ¼sinasyon:** DÄ±ÅŸ kaynaklardan getirilen doÄŸrulanabilir veriler, modelin yanlÄ±ÅŸ veya uydurma bilgiler Ã¼retme riskini azaltÄ±r. Model, zeminlenmiÅŸ (grounded) olduÄŸunda, parametrelerine â€œbaked-inâ€ hatalÄ± bilgiler yerine gÃ¼venilir kaynaklara dayanÄ±r. Bu da LLMâ€™nin halÃ¼sinasyon ihtimalini dÃ¼ÅŸÃ¼rÃ¼r.
- **Kaynak ÅeffaflÄ±ÄŸÄ±:** RAG Ã§Ä±ktÄ±larÄ±nÄ±n dayandÄ±ÄŸÄ± bilgi parÃ§alarÄ± genellikle izlenebilir durumdadÄ±r. Getirilen belgelerin kaynaÄŸÄ± bilindiÄŸi iÃ§in modelin cevabÄ±nÄ±n hangi kaynaktan geldiÄŸi gÃ¶rÃ¼lebilir; dolayÄ±sÄ±yla kullanÄ±cÄ± gerektiÄŸinde cevabÄ± doÄŸrulayabilir veya hatalÄ± ise kaynaÄŸÄ±nÄ± gÃ¼ncelleyebilirâ€‹. Klasik modellerde ise cevabÄ±n kaynaÄŸÄ± modelin iÃ§inde belirsiz bir ÅŸekilde gÃ¶mÃ¼lÃ¼dÃ¼r.
- **Esneklik ve DÃ¼ÅŸÃ¼k BakÄ±m Maliyeti:** YalnÄ±z LLM kullanan bir sistemde modelin bilgi tazelemesi iÃ§in yeniden eÄŸitme veya ek eÄŸitim (fine-tuning) gerekir ki bu hem zaman hem kaynak aÃ§Ä±sÄ±ndan maliyetlidir. RAG yaklaÅŸÄ±mÄ±nda ise bilgi tabanÄ±nÄ± gÃ¼ncellemek (Ã¶r. yeni dokÃ¼manlar eklemek) yeterli olduÄŸundan bakÄ±m maliyeti daha dÃ¼ÅŸÃ¼ktÃ¼râ€‹. Bu yÃ¶ntem, sÄ±k sÄ±k model eÄŸitimi yapmaktan daha hesaplÄ± bir yoldurâ€‹. 

DiÄŸer yandan, RAG modelleri bu ek bileÅŸenleri nedeniyle klasik modellere gÃ¶re daha karmaÅŸÄ±k bir mimariye sahiptir. Bu karmaÅŸÄ±klÄ±k, doÄŸru bir ÅŸekilde yÃ¶netilmezse performans darboÄŸazlarÄ± veya entegrasyon sorunlarÄ± oluÅŸturabilir (aÅŸaÄŸÄ±da Zorluklar bÃ¶lÃ¼mÃ¼nde ele alÄ±nacaktÄ±r).

## Teknik BileÅŸenler

### Transformer Modelleri

RAG sistemlerinin temelinde genellikle Transformer mimarisiyle eÄŸitilmiÅŸ dil modelleri bulunur. Transformer, Googleâ€™Ä±n 2017â€™deki â€œAttention is All You Needâ€ makalesi ile tanÄ±tÄ±lan, dizi verilerindeki iliÅŸkileri Ã¶z-dikkat (self-attention) mekanizmasÄ±yla Ã¶ÄŸrenen bir sinir aÄŸÄ± tÃ¼rÃ¼dÃ¼r. Bu mimari, uzun metin dizilerinde bile uzak kelimeler arasÄ±ndaki baÄŸÄ±ntÄ±larÄ± verimli bir ÅŸekilde yakalayabilirâ€‹.Ã–rneÄŸin bir Transformer modeli, bir cÃ¼mlenin baÅŸÄ±ndaki kelime ile sonundaki kelime arasÄ±ndaki iliÅŸkiyi tekrar tekrar Ã¼zerinden geÃ§meden (tekrarlayan aÄŸlar gibi) doÄŸrudan dikkat mekanizmasÄ± ile Ã¶ÄŸrenirâ€‹. BERT, GPT, T5 gibi gÃ¼ncel bÃ¼yÃ¼k dil modelleri Transformer tabanlÄ±dÄ±r ve metin anlama ile metin Ã¼retme gÃ¶revlerinde son derece baÅŸarÄ±lÄ±dÄ±r.

RAG mimarisinde Transformer modelleri iki rolde karÅŸÄ±mÄ±za Ã§Ä±kar:

* **Soru/KullanÄ±cÄ± sorgusu kodlayÄ±cÄ± (encoder):** Girilen soruyu veya promptâ€™u vektÃ¶r uzayÄ±nda temsile dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r. Ã–rneÄŸin bir DPR (Dense Passage Retriever) modelinde, Transformer bazlÄ± bir kodlayÄ±cÄ±, kullanÄ±cÄ± sorusunu embedding denilen bir sayÄ±sal vektÃ¶re Ã§evirir.
* **Cevap Ã¼reten model (decoder/generator):** Bu, genellikle bir seq2seq (dizi-dizi) Transformer modelidir (BART, T5 gibi) ya da bir GPT tÃ¼revi olabilir. Retrieverâ€™Ä±n getirdiÄŸi metin parÃ§alarÄ±nÄ± ve orijinal soruyu birlikte girdi olarak alÄ±r ve doÄŸal dil Ã§Ä±ktÄ± (cevap) Ã¼retir. Transformerâ€™Ä±n gÃ¼Ã§lÃ¼ dil modelleme kabiliyeti sayesinde model, gelen ekstra bilgileri baÄŸlama oturtup tutarlÄ± bir yanÄ±t oluÅŸturur.

Ã–zetle, Transformer modelleri RAGâ€™Ä±n hem bellek hem beyin iÅŸlevini gÃ¶rÃ¼r: Bir yandan dil bilgisini Ã¶ÄŸrenmiÅŸ bir Ã¼retici, diÄŸer yandan anlamsal arama yapabilen bir kodlayÄ±cÄ± olarak gÃ¶rev yaparlar.

### Embeddingâ€™ler ve vektÃ¶r veri tabanlarÄ±

**Embedding**, metin gibi yapÄ±landÄ±rÄ±lmamÄ±ÅŸ verileri sayÄ±sal vektÃ¶rler olarak temsil etme yÃ¶ntemidir. Bir cÃ¼mle veya belge, eÄŸitilmiÅŸ bir dil modeli yardÄ±mÄ±yla Ã§ok boyutlu bir uzayda noktaya (vektÃ¶re) dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lebilir; bu vektÃ¶r, metnin anlamsal iÃ§eriÄŸini kodlar. Ã–rneÄŸin â€œAnkara TÃ¼rkiyeâ€™nin baÅŸkentidirâ€ cÃ¼mlesinin embedding vektÃ¶rÃ¼, â€œbaÅŸkentâ€ ve â€œTÃ¼rkiyeâ€ gibi kavramlarÄ± yansÄ±tan bir konumda olacaktÄ±r. RAG sistemlerinde embedding modelleri, sorularÄ± ve dokÃ¼manlarÄ± aynÄ± vektÃ¶r uzayÄ±na aktararak anlamsal karÅŸÄ±laÅŸtÄ±rma yapÄ±lmasÄ±nÄ± mÃ¼mkÃ¼n kÄ±larâ€‹.

Elde edilen bu vektÃ¶rleri depolamak ve hÄ±zlÄ± arama yapabilmek iÃ§in vektÃ¶r veri tabanlarÄ± kullanÄ±lÄ±r. VektÃ¶r veri tabanÄ±, her belgenin embeddingâ€™ini saklar ve bir arama sorgusunun vektÃ¶rÃ¼ ile koleksiyondaki vektÃ¶rler arasÄ±nda benzerlik sorgularÄ± yapar. Pinecone, Weaviate, Qdrant gibi Ã¶zel amaÃ§lÄ± veritabanlarÄ± bu alanda yaygÄ±ndÄ±r. Bu veritabanlarÄ±, milyarlarca vektÃ¶r arasÄ±nda milisaniyeler iÃ§inde en yakÄ±n vektÃ¶rleri bulabilecek ÅŸekilde optimize edilir. Ã–rneÄŸin, bir RAG uygulamasÄ±nda ÅŸirket dokÃ¼manlarÄ±nÄ±n vektÃ¶rlerini iÃ§eren bir veritabanÄ± olduÄŸunu dÃ¼ÅŸÃ¼nelim; kullanÄ±cÄ± â€œyÄ±llÄ±k izin politikasÄ± nedir?â€ diye sorduÄŸunda, sorgu embeddingâ€™i hesaplanÄ±r ve bu veritabanÄ±nda en benzer vektÃ¶rler (yÄ±llÄ±k izin politikasÄ±nÄ±n geÃ§tiÄŸi dokÃ¼manlardan) hÄ±zla getirilir. Bu getirme iÅŸlemi Ã§oÄŸunlukla koÅŸul **komÅŸu aramasÄ± (nearest neighbor search)** algoritmalarÄ±yla gerÃ§ekleÅŸtirilir.


 Embeddingâ€™ler, metinleri sayÄ±sal olarak karÅŸÄ±laÅŸtÄ±rÄ±labilir hale getirirken; vektÃ¶r veri tabanlarÄ± da bu karÅŸÄ±laÅŸtÄ±rmayÄ± bÃ¼yÃ¼k Ã¶lÃ§ekli veri iÃ§in mÃ¼mkÃ¼n kÄ±lar. SonuÃ§ta RAG sistemi, soruyla en alakalÄ± bilgi parÃ§alarÄ±nÄ± tespit edip getirebilir.


### Bilgi getirme mekanizmalarÄ±

Bilgi getirme, sparse (seyrek) ve dense (yoÄŸun) olmak Ã¼zere iki temel yaklaÅŸÄ±mla gerÃ§ekleÅŸtirilebilir:

* **Sparse Retrieval (Anahtar Kelime TabanlÄ± Arama):**  Bu geleneksel arama yÃ¶ntemidir. DokÃ¼manlar iÃ§erisinde anahtar kelime eÅŸleÅŸmelerine dayanÄ±r; TF-IDF, BM25 gibi algoritmalar metinlerdeki terimlerin frekansÄ±na ve daÄŸÄ±lÄ±mÄ±na bakarak ilgili sonuÃ§larÄ± bulur. Anahtar kelime aramasÄ±, bir sorguda geÃ§en kelimelerin aynÄ± ÅŸekilde dokÃ¼manda geÃ§mesine dayanÄ±r. Ã–rneÄŸin, â€œbaÅŸkent nÃ¼fusu Ankaraâ€ ÅŸeklinde bir sorgu iÃ§in sparse arama, iÃ§erisinde bu kelimelerin sÄ±k geÃ§tiÄŸi dokÃ¼manlarÄ± yÃ¼ksek skorlarsa, â€œAnkaraâ€ kelimesi geÃ§meyen ancak aynÄ± anlama gelen bir metni (Ã¶rneÄŸin â€œTÃ¼rkiyeâ€™nin yÃ¶netim merkeziâ€) atlayabilir. AvantajÄ±, sonuÃ§larÄ±n hangi kelimelerden eÅŸleÅŸtiÄŸi anlaÅŸÄ±labilir (yorumlanabilir) olmasÄ± ve genelde daha dÃ¼ÅŸÃ¼k kaynak gerektirmesidir. Ancak eÅŸ anlamlÄ± ifadeleri veya baÄŸlamsal iliÅŸkileri yakalamakta yetersiz kalabilirâ€‹.
* **Dense Retrieval (VektÃ¶r TabanlÄ± Arama):** Bu yaklaÅŸÄ±m, yukarÄ±da bahsedilen embeddingâ€™leri kullanÄ±r ve anlamsal benzerlik odaklÄ±dÄ±r. Sorgu ve dokÃ¼manlar vektÃ¶r uzayÄ±nda temsil edilir; arama iÅŸlemi, sorgu vektÃ¶rÃ¼ne en yakÄ±n vektÃ¶rleri bulmaktÄ±r. Bu sayede, tam kelime eÅŸleÅŸmesi olmasa bile benzer anlamlÄ± iÃ§erikler yakalanabilir. Ã–rneÄŸin, â€œbaÅŸkent nÃ¼fusu Ankaraâ€ sorgusu dense aramada, â€œTÃ¼rkiyeâ€™nin baÅŸkentinin nÃ¼fusuâ€¦â€ diye baÅŸlayan bir dokÃ¼manÄ± yÃ¼ksek olasÄ±lÄ±kla bulacaktÄ±r, Ã§Ã¼nkÃ¼ vektÃ¶r temsilleri anlamsal olarak yakÄ±n olacaktÄ±r. Dense retrieval genellikle derin Ã¶ÄŸrenme modellerinin gÃ¼cÃ¼nÃ¼ kullandÄ±ÄŸÄ± iÃ§in daha isabetli anlamsal eÅŸleÅŸmeler sunar, ancak bÃ¼yÃ¼k vektÃ¶r koleksiyonlarÄ±nda hÄ±zlÄ± arama yapmak iÃ§in Ã¶zel altyapÄ± (vektÃ¶r veritabanÄ±) gerektirir. GÃ¼nÃ¼mÃ¼zde RAG sistemlerinde dense retrieval sÄ±k tercih edilir, zira LLMâ€™lerin dil bilgisini tamamlayÄ±cÄ± bir ÅŸekilde anlamsal arama yapabilirâ€‹. 


Bir RAG uygulamasÄ±nda bu iki yÃ¶ntem bir arada da kullanÄ±labilir: Ã–rneÄŸin Ã¶nce sparse yÃ¶ntemle hÄ±zlÄ± bir Ã¶n eleme yapÄ±lÄ±p, sonra kalan adaylar arasÄ±ndan dense yÃ¶ntemle en iyiler seÃ§ilebilir. Ancak genel olarak, dense retrieval modern RAG sistemlerinin belkemiÄŸidir, Ã§Ã¼nkÃ¼ dil modellerinin anlayabildiÄŸi ÅŸekilde kavramsal benzerlikleri yakalar. Ã–zetlemek gerekirse, sparse arama kelimelere, dense arama anlamlara odaklanÄ±r.

### RAG Mimarisi

RAG mimarisi, bir getirici (retriever) modÃ¼lÃ¼ ile bir Ã¼retici (generator) modÃ¼lÃ¼ olmak Ã¼zere iki ana bileÅŸeni iÃ§erir. AÅŸaÄŸÄ±daki ÅŸema, RAG frameworkâ€™Ã¼nÃ¼n modÃ¼ler yapÄ±sÄ±nÄ± ve bir kullanÄ±cÄ± isteÄŸinden yanÄ±t oluÅŸana dek gerÃ§ekleÅŸen veri akÄ±ÅŸÄ±nÄ± gÃ¶stermektedirâ€‹.

![image](https://github.com/user-attachments/assets/337d8fe9-eabc-420f-9e4e-52d9d1c334bf)

1) KullanÄ±cÄ± bir istek/prompt giriÅŸi yapar.
2) Bu istek, Retrieval Model (Getirici model) tarafÄ±ndan alÄ±nÄ±p kurumun dahili kaynaklarÄ± gibi harici bilgi kaynaklarÄ±nda arama yapmak Ã¼zere iÅŸlenir.
3) Retrieval Model, yapÄ±landÄ±rÄ±lmÄ±ÅŸ veritabanlarÄ±ndan veya belge koleksiyonlarÄ±ndan ilgili olabilecek kayÄ±tlarÄ± sorgular ve bulduÄŸu sonuÃ§larÄ± kullanarak kullanÄ±cÄ±nÄ±n orijinal sorgusunu ek baÄŸlamla zenginleÅŸtirir (yani sorguya uygun baÄŸlamsal bilgilerle birleÅŸtirir).
4) ArdÄ±ndan bu baÄŸlamla zenginleÅŸtirilmiÅŸ prompt, Generation Model (LLM) olarak adlandÄ±rÄ±lan Ã¼retici modele iletilir. LLM, gelen ek bilgiyle desteklenmiÅŸ promptâ€™u iÅŸler ve kullanÄ±cÄ±ya yÃ¶nelik nihai yanÄ±tÄ± oluÅŸtururâ€‹


YukarÄ±daki dÃ¶ngÃ¼, kullanÄ±cÄ±nÄ±n her sorusu iÃ§in tekrar eder. Ä°yi bir RAG sistemi, tÃ¼m bu adÄ±mlarÄ± olabildiÄŸince hÄ±zlÄ± (tercihen birkaÃ§Ä± saniye iÃ§inde) yaparak gerÃ§ek zamanlÄ± sohbet deneyimi sunabilirâ€‹. Ã–rneÄŸin, bir mÃ¼ÅŸteri destek sohbet botunda kullanÄ±cÄ± â€œSipariÅŸim ne zaman teslim edilir?â€ diye sorduÄŸunda, retrieval modÃ¼lÃ¼ sipariÅŸ veritabanÄ±ndan ilgili kayÄ±tlarÄ± Ã§ekip LLMâ€™e verir; LLM de bu bilgilerle donanmÄ±ÅŸ bir yanÄ±t Ã¼retir.

RAG mimarisinde her modÃ¼l ayrÄ± geliÅŸtirilebilir ve optimize edilebilir: Getirici kÄ±sÄ±m iÃ§in istenirse farklÄ± arama algoritmalarÄ± denenebilir, Ã¼retici kÄ±sÄ±m iÃ§in farklÄ± LLMâ€™ler kullanÄ±labilir. Bu modÃ¼lerlik sayesinde, klasik tek-parÃ§a LLM Ã§Ã¶zÃ¼mlerine gÃ¶re RAG sistemleri daha esnek ve Ã¶lÃ§eklenebilir hale gelir. Ancak modÃ¼ller arasÄ± entegrasyonun iyi tasarlanmasÄ± Ã¶nemlidir; aksi takdirde getirilen bilginin yanlÄ±ÅŸ kullanÄ±mÄ± veya gecikmeler gibi sorunlar ortaya Ã§Ä±kabilir.

## Avantaj ve Zorluklar

RAG, doÄŸru uygulandÄ±ÄŸÄ±nda Ã¼retken yapay zekÃ¢ sistemlerine Ã¶nemli avantajlar kazandÄ±rÄ±r:


* **GÃ¼ncellik**: LLMâ€™nin eÄŸitim verilerinde bulunmayan en yeni bilgilere eriÅŸebilir. Ã–rneÄŸin, RAG sayesinde bir model, dÃ¼n yayÄ±nlanmÄ±ÅŸ bir makaledeki bilgiyi bile yanÄ±tÄ±na katabilir; bu, eÄŸitimi aylar Ã¶nce tamamlanmÄ±ÅŸ klasik bir model iÃ§in mÃ¼mkÃ¼n deÄŸildirâ€‹.
* SÃ¼rekli Ã–ÄŸrenme ve GÃ¼ncelleme: Bilgi kaynaÄŸÄ± (Ã¶rn. belge veri tabanÄ±) kolaylÄ±kla gÃ¼ncellenebilir olduÄŸundan, sistemi baÅŸtan eÄŸitmeye gerek kalmadan yeni bilgilere uyum saÄŸlanÄ±r. Bu, daha dÃ¼ÅŸÃ¼k bakÄ±m maliyeti ve daha hÄ±zlÄ± adaptasyon demektirâ€‹.
* BaÄŸlam ve Ã–zelleÅŸtirme: RAGâ€™Ä±n bilgi deposu, belirli bir alan veya kuruma Ã¶zgÃ¼ verilerle doldurulabilir. BÃ¶ylece model, genel dÃ¼nya bilgisinin yanÄ±nda duruma Ã¶zel detaylarÄ± da bilebilir. SonuÃ§ olarak yanÄ±tlar, kullanÄ±cÄ±nÄ±n bulunduÄŸu baÄŸlama Ã§ok daha uygun hale gelirâ€‹
* Ä°zlenebilirlik ve DÃ¼zeltilebilirlik: RAG modelleri, yanÄ±tlarÄ± desteklemek iÃ§in kullandÄ±klarÄ± kaynaklarÄ± bildiÄŸi iÃ§in ÅŸeffaflÄ±k sunar. Bir yanÄ±tÄ±n hangi dokÃ¼mana dayandÄ±ÄŸÄ± tespit edilebilir; eÄŸer hata varsa ilgili dokÃ¼man dÃ¼zeltilerek modelin gelecekteki Ã§Ä±ktÄ±larÄ± da dÃ¼zeltilebilirâ€‹. Bu, kurumsal uygulamalarda denetim ve doÄŸrulama aÃ§Ä±sÄ±ndan bÃ¼yÃ¼k avantajdÄ±r.
* Azalan HalÃ¼sinasyon ve Artan DoÄŸruluk: Model, cevabÄ±nÄ± harici belgelerle temellendirdiÄŸi iÃ§in uydurma veya yanlÄ±ÅŸ bilgi verme olasÄ±lÄ±ÄŸÄ± dÃ¼ÅŸer. RAG kullanÄ±mÄ±, LLMâ€™nin â€œkendi hafÄ±zasÄ±ndakiâ€ tutarsÄ±zlÄ±klardansa gerÃ§ek kaynaklara dayanmasÄ±nÄ± saÄŸlarâ€‹.

## VektÃ¶r Veri TabanÄ±: ChromaDB

 **ChromaDB**, embeddingâ€™leri saklayan ve arayan bir vektÃ¶r veritabanÄ±dÄ±r.

* Embeddingâ€™leri saklar
* SorgularÄ± vektÃ¶r benzerliÄŸine gÃ¶re arar
* RAG sistemlerine kolay entegre edilir.

### Kurulum: ChromaDB ile Ä°lk Uygulama

**1-Sanal Ortam OluÅŸturma:**

``` python
python3 -m venv venv
source venv/bin/activate
``` 

**2-Sanal Ortam OluÅŸturma:**

``` python
pip install chromadb
``` 

### ChromaDBâ€™de Koleksiyon OluÅŸturma

``` python
import chromadb
client = chromadb.PersistentClient(path="./vectorstore")
collection = client.get_or_create_collection(name="programlama")
```

ğŸ“ Koleksiyon = SQL'deki tablo gibi dÃ¼ÅŸÃ¼nÃ¼lÃ¼r.

### Veri Ekleme

``` python
collection.add(
  documents=[
    "Python harika bir dildir.",
    "Dosya iÅŸlemleri iÃ§in context manager kullanÄ±lÄ±r.",
    "Type hints, kodu belgelendirmeye yarar."
  ],
  metadatas=[
    {"sayfa": 2}, {"sayfa": 5}, {"sayfa": 7}
  ],
  ids=["1", "2", "3"]
)

```

### Sorgu Benzerlik AramasÄ±


``` python
result = collection.query(
  query_texts=["Python"],
  n_results=2
)
print(result)
```

ğŸ“Œ Sorgunuz embed edilir ve benzer dÃ¶kÃ¼manlar vektÃ¶rel olarak karÅŸÄ±laÅŸtÄ±rÄ±lÄ±r.

### GÃ¼ncelleme


``` python
collection.update(
  documents=["GÃ¼ncellenmiÅŸ iÃ§erik"],
  ids=["2"],
  metadatas=[{"sayfa": 99}]
)
```

### Silme

``` python
collection.delete(ids=["3"])
```

### Filtreleme (where)


``` python
collection.get(
  where={"sayfa": {"$lt": 100}},
  include=["documents"]
)
```


