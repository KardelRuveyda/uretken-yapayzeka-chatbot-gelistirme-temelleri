
# Advanced RAG + Self-Reflection: Query Analysis Workflow

![alt text](image.png)

Retrieval-Augmented Generation (RAG), bÃ¼yÃ¼k dil modellerinin (LLM - Large Language Models) daha anlamlÄ± ve doÄŸru yanÄ±tlar verebilmesi iÃ§in bir bilgi getirme (retrieval) mekanizmasÄ±nÄ± metin Ã¼retimi (generation) ile birleÅŸtiren bir yapay zeka mimarisidir.

Normalde, LLM'ler sadece kendi eÄŸitim verisiyle sÄ±nÄ±rlÄ± bilgi saÄŸlarken, RAG sayesinde model, dÄ±ÅŸarÄ±dan (PDF, veri tabanÄ±, web sayfasÄ± vb.) belge alarak daha kanÄ±t dayalÄ± ve isabetli cevaplar verebilir.

> Ã–rneÄŸin: Sadece GPT-4'e "TÃ¼rkiye'nin gÃ¼ncel nÃ¼fusu nedir?" derseniz doÄŸru bir yanÄ±t veremeyebilir, Ã§Ã¼nkÃ¼ eÄŸitim verisi geÃ§miÅŸte kalmÄ±ÅŸtÄ±r. Ama RAG sistemi bu soruda TÃœÄ°K gibi gÃ¼ncel bir kaynaktan bilgi Ã§ekerek doÄŸru veriyi sunabilir.

Self-reflection ise bu mekanizmayÄ± daha da gÃ¼Ã§lendirir: Model cevabÄ±nÄ± oluÅŸturduktan sonra kendine ÅŸu sorularÄ± sorar:
- GerÃ§ekten kaynaklardan alÄ±ntÄ± mÄ± yaptÄ±m?
- CevabÄ±m yeterince aÃ§Ä±k mÄ±?
- Uydurma bilgi iÃ§eriyor muyum?

Bu sayede Ã§Ä±ktÄ± kalitesi Ã¶nemli Ã¶lÃ§Ã¼de artar.

---

## ğŸ”¢ 1. Query Analysis (Sorgu Analizi)

### âœï¸ AmaÃ§:
KullanÄ±cÄ±dan gelen sorunun hangi yolla iÅŸleneceÄŸini belirlemek. Elimizdeki veri indeksleri bu soruya cevap verebiliyor mu, yoksa web aramasÄ±na mÄ± Ã§Ä±kmak gerekiyor?

### ğŸ” NasÄ±l iÅŸler?
1. KullanÄ±cÄ± bir soru sorar: "GPT modelleri ile RAG arasÄ±ndaki fark nedir?"
2. Bu soru Query Analysis modÃ¼lÃ¼ne gelir.
3. Bu modÃ¼l soruyu anlamaya Ã§alÄ±ÅŸÄ±r:
   - ğŸ”´ Anahtar kelimeler: "GPT", "RAG", "fark"
   - ğŸ¤– Bu kelimeler sistemin indekslediÄŸi teknik belgelerde mevcut mu?
4. Bu kontrol sonrasÄ± iki olasÄ±lÄ±k doÄŸar:
   - âœ… **[Related to index]**: Soruya yanÄ±t verebilecek belgeler sistemde vardÄ±r. RAG + Self-reflection hattÄ±na yÃ¶nlendirilir.
   - âŒ **[Unrelated to index]**: Sistem bu soruya dair hiÃ§bir belgi barÄ±ndÄ±rmÄ±yor. Bu durumda web search hattÄ± devreye girer.
5. ğŸ” (Opsiyonel) GeliÅŸmiÅŸ sistemlerde Query Analysis Node, soruyu daha iyi yÃ¶nlendirmek iÃ§in Ã¶n iÅŸlemden geÃ§irir: yeniden yazma, keyword Ã§Ä±karÄ±mÄ±, hatta kullanÄ±cÄ± niyeti sÄ±nÄ±flandÄ±rmasÄ± (intent classification).

### ğŸ§µ DetaylÄ± Senaryo:
> Soru: "2025 yÄ±lÄ±nda en verimli yapay zeka modeli hangisi?"
- Query Analysis modÃ¼lÃ¼ bu sorunun teknik bir karÅŸÄ±lÄ±ÄŸÄ± olup olmadÄ±ÄŸÄ±nÄ± indekslerde kontrol eder.
- EÄŸer eÄŸitim setlerinde 2025'e dair bilgi yoksa: `unrelated to index`
- Web search modÃ¼lÃ¼ne yÃ¶nlendirilir.

---

## ğŸ§  2. RAG + Self-Reflection (YansÄ±malÄ± Bilgi Getirme)

### ğŸ“„ AmaÃ§:
KapsamlÄ± ve kaliteli cevap Ã¼retimi iÃ§in ilgili belgeleri getir, deÄŸerlendir, cevap oluÅŸtur ve Ã§Ä±kan sonucu tekrar gÃ¶zden geÃ§irerek gerekirse yeniden dene.

### ğŸ”· DetaylÄ± AdÄ±mlar:

#### â— 1. Retrieve (Node) â†’ "Belgeleri getir"
- Sistem, kullanÄ±cÄ±nÄ±n sorusunu vektÃ¶r formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r (embedding).
- Bu vektÃ¶r, Chroma, Pinecone, FAISS gibi bir vektÃ¶r veritabanÄ±nda aratÄ±lÄ±r.
- En alakalÄ± (top-k) belgeler getirilir.
- Ã–rnek: Soru "RAG mimarisi nedir?" â†’ En alakalÄ± 5 belge Ã§ekilir.

#### â— 2. Grade (Node) â†’ "Belgeleri deÄŸerlendir"
- Getirilen belgelerin soruyla ne kadar Ã¶rtÃ¼ÅŸtÃ¼ÄŸÃ¼ Ã¶lÃ§Ã¼lÃ¼r.
- Her belgenin "relevance score"u hesaplanÄ±r. EÅŸik deÄŸerin altÄ±nda kalanlar elenir.
- Bu adÄ±m sayesinde "yanlÄ±ÅŸ pozitif" belgeler temizlenir.

#### ğŸ”¹ Karar NoktasÄ±: Docs Relevant?
- Belgeler yeterince alakalÄ± mÄ±?
   - âœ… Evet â†’ Cevap Ã¼ret.
   - âŒ HayÄ±r â†’ Soru yeniden yazÄ±lÄ±r, daha isabetli hale getirilir ve retrieval yeniden baÅŸlar.

#### â— 3. Generate (Node) â†’ "Cevap oluÅŸtur"
- Kalan belgeler baÄŸlama dahil edilir.
- LLM, bu belgeleri kullanarak bir yanÄ±t Ã¼retir.
- Genellikle prompt: `"Sadece aÅŸaÄŸÄ±daki belgelere dayanarak soruyu yanÄ±tla..."`

#### â— 4. Hallucination KontrolÃ¼
- Modelin cevabÄ±nda "kaynakta olmayan" bilgi var mÄ±?
- EÄŸer varsa, self-reflection tetiklenir.
- Bu noktada cevabÄ±n belgelere dayalÄ±lÄ±ÄŸÄ± sorgulanÄ±r. Gerekirse yanÄ±t silinir ve baÅŸtan baÅŸlanÄ±r.

#### â— 5. Cevap GerÃ§ekten Soruya Cevap Veriyor mu?
- Semantik olarak cevap ile soru uyumlu mu?
- Bu noktada "QA alignment" Ã¶lÃ§Ã¼mleri, metin benzerlik algoritmalarÄ± veya ikinci bir LLM kullanÄ±larak cevap denetlenebilir.

#### â— 6. Re-write Question (Node)
- Sorunun dil yapÄ±sÄ± veya baÄŸlamÄ± belki iyi deÄŸil.
- Bu adÄ±mda sistem soruyu yeniden yazar:
  > "Onun verimliliÄŸi nasÄ±ldÄ±r?" âŒ
  > "GPT-4â€™Ã¼n inference sÃ¼resi diÄŸer modellere gÃ¶re nasÄ±ldÄ±r?" âœ…

#### ğŸ” TÃ¼m bu dÃ¶ngÃ¼, kaliteli cevap alÄ±nÄ±ncaya kadar tekrar edilebilir.

---

## ğŸŒ 3. Web Search (Index-DÄ±ÅŸÄ± Sorgular)

### ğŸŒ AmaÃ§:
Sistem iÃ§inde belgeler yoksa, dÄ±ÅŸ kaynaklardan gerÃ§ek zamanlÄ± bilgi Ã§ek.

### ğŸ”¹ DetaylÄ± AkÄ±ÅŸ:
1. Soru "Query Analysis" tarafÄ±ndan unrelated olarak iÅŸaretlenir.
2. Web Search Node aktifleÅŸir:
   - Google/Bing/SerpAPI Ã¼zerinden arama yapÄ±lÄ±r.
   - API Ã§Ä±ktÄ±sÄ± Ã¶zetlenir ya da ilgili kÄ±sÄ±mlar alÄ±nÄ±r.
3. Generate Node yanÄ±t oluÅŸturur:
   - Web verisi prompt'a eklenir: "AÅŸaÄŸÄ±daki iÃ§erikleri referans alarak..."
4. YanÄ±t doÄŸrudan kullanÄ±cÄ±ya iletilir.

### ğŸ§ª Ek Not:
- Bu hat gerÃ§ek zamanlÄ± veriye ihtiyaÃ§ olan senaryolar iÃ§in idealdir (haberler, son raporlar, gÃ¼ncel fiyatlar, hava durumu).

---

## âš™ï¸ Teknik Detaylar

### Node Nedir?
Bir node, sistem iÃ§indeki iÅŸlem adÄ±mÄ±dÄ±r. 
- Fonksiyon, API endpointâ€™i ya da bir LLM Ã§aÄŸrÄ±sÄ± olabilir.
- Her node bir iÅŸi yapar: getir, deÄŸerlendir, Ã¼ret, kontrol et gibi.

### Re-write Node Neden Ã–nemlidir?
Soru Ã§ok genel veya baÄŸlam dÄ±ÅŸÄ± olabilir. Bu durumda model:
- Soruya baÄŸlam ekler
- Hedefi netleÅŸtirir
- Retrieval kalitesini artÄ±rÄ±r

### Hallucination Detection MekanizmasÄ±:
- Modelin eÄŸilimsel olarak "uydurma" bilgi Ã¼retmesini Ã¶nlemek iÃ§in mutlaka uygulanmalÄ±dÄ±r.
- Kurallar:
  - Belgeden alÄ±ntÄ± olmayan cÃ¼mleler?
  - Tahmine dayalÄ± cevaplar?
  - Belgeye referans vermeyen bilgiler?

---

## ğŸ“š Ek Kaynaklar
- [RAG: Lewis et al., 2020](https://arxiv.org/abs/2005.11401)
- [LangChain RAG Docs](https://docs.langchain.com/docs/modules/data_connection/retrieval)
- [OpenAI Self-Reflection](https://platform.openai.com/docs/guides/)
- [Chroma Vector Store](https://www.trychroma.com)

---

## âœ¨ SonuÃ§: GeliÅŸmiÅŸ RAG Sistemi Ne KazandÄ±rÄ±r?
Bu yapÄ±, sadece cevap Ã¼retmekle kalmaz, cevabÄ±n kalitesini gÃ¼vence altÄ±na alÄ±r.
- âŒ Uydurma bilgi Ã¼retimi azalÄ±r
- âœ… Kaynak bazlÄ± doÄŸruluk artar
- ğŸ” SÃ¼rekli kendini geliÅŸtiren bir yapÄ± oluÅŸur

> Ã–ÄŸrenciler iÃ§in Ã¶neri: Bu yapÄ±yÄ± adÄ±m adÄ±m bir kaÄŸÄ±da Ã§izin. Her adÄ±mÄ± bir kutucukla sembolize edin. Soruyu alÄ±n, yÃ¶nlendirin, belge alÄ±n, kontrol edin, Ã¼retin, sonra sorgulayÄ±n.

Bu, modern yapay zekanÄ±n temel refleksidir: "Sadece konuÅŸma, dÃ¼ÅŸÃ¼n, kontrol et ve gerekiyorsa susup tekrar Ã¶ÄŸren."
