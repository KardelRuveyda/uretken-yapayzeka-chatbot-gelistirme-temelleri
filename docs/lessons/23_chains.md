# ğŸ§  `graph/chains/` KlasÃ¶rÃ¼ â€“ Ne Ä°ÅŸe Yarar? + SatÄ±r SatÄ±r AÃ§Ä±klama

Bu klasÃ¶r, LangChain + LangGraph sisteminde zincirleri (chain) iÃ§erir. Her zincir belirli bir iÅŸi otomatikleÅŸtirir:
Ã¶rneÄŸin cevap Ã¼retme, puanlama, yÃ¶nlendirme gibi. AÅŸaÄŸÄ±da her dosyanÄ±n **amacÄ±** ve **satÄ±r satÄ±r aÃ§Ä±klamasÄ±** yer alÄ±r.

---

## ğŸ” 1. `generation.py` â€“ Cevap Ãœreten Ana Zincir

### Ne Yapar?

- KullanÄ±cÄ±nÄ±n sorusunu ve belgeleri modele verir.
- OpenAI LLM modeli ile cevap Ã¼retir.
- Bu cevabÄ± sade metin olarak dÃ¶ner.

### Kod ve AÃ§Ä±klama

```python
from langchain import hub  # HazÄ±r prompt ÅŸablonlarÄ± iÃ§in merkezi sistem
from langchain_core.output_parsers import StrOutputParser  # Model Ã§Ä±ktÄ±sÄ±nÄ± dÃ¼z metne Ã§eviren yapÄ±
from langchain_openai import ChatOpenAI  # OpenAI'nin sohbet modelini kullanmak iÃ§in
```

```python
llm = ChatOpenAI(temperature=0)  # KararlÄ± (deterministik) cevaplar iÃ§in sÄ±caklÄ±k 0 yapÄ±lÄ±r
prompt = hub.pull("rlm/rag-prompt")  # LangChain Hub'dan "retrieval-based QA" promptu alÄ±nÄ±r
```

```python
generation_chain = prompt | llm | StrOutputParser()  # Zincir oluÅŸturulur: prompt â†’ model â†’ string Ã§Ä±ktÄ±
```

---

## âœ… 2. `answer_grader.py` â€“ Cevap DoÄŸru mu?

### Ne Yapar?

- Modelin cevabÄ± soruyu gerÃ§ekten yanÄ±tlÄ±yor mu?
- LLM'e "Bu cevap soruyu aÃ§Ä±klÄ±yor mu?" diye sorar.
- Binary cevap dÃ¶ner: `yes` veya `no`.

### Kod ve AÃ§Ä±klama

```python
from langchain_core.prompts import ChatPromptTemplate  # LLM'e gidecek mesaj formatÄ±
from langchain_core.pydantic_v1 import BaseModel, Field  # YapÄ±sal veri ÅŸemasÄ± tanÄ±mlamak iÃ§in
from langchain_core.runnables import RunnableSequence  # Zinciri tanÄ±mlamak iÃ§in
from langchain_openai import ChatOpenAI  # OpenAI LLM
from dotenv import load_dotenv  # Ortam deÄŸiÅŸkenlerini yÃ¼klemek iÃ§in
```

```python
load_dotenv()  # .env dosyasÄ±ndaki anahtarlarÄ± belleÄŸe alÄ±r
class GradeAnswer(BaseModel):
    binary_score: bool = Field(
        description="Answer addresses the question 'yes' or 'no'"
    )
```

```python
llm = ChatOpenAI(temperature=0)
structured_llm_grader = llm.with_structured_output(GradeAnswer)  # Modelden yapÄ±landÄ±rÄ±lmÄ±ÅŸ Ã§Ä±ktÄ± bekleriz
```

```python
system = """You are a grader assessing whether an answer addresses the question.
Give a binary score 'yes' or 'no'."""

answer_prompt = ChatPromptTemplate.from_messages([
    ("system", system),
    ("human", "User question: {question}\n\n LLM Generation: {generation}")
])
```

```python
answer_grader: RunnableSequence = answer_prompt | structured_llm_grader  # Zincir: prompt â†’ model
```

---

## ğŸ“ 3. `retrieval_grader.py` â€“ Belge AlakalÄ± mÄ±?

### Ne Yapar?

- Getirilen belge soruyla ilgili mi?
- LLM'e bu soruyu sorar ve `yes/no` cevabÄ± alÄ±r.

### Kod ve AÃ§Ä±klama

```python
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.pydantic_v1 import BaseModel, Field
from langchain_openai import ChatOpenAI
```

```python
llm = ChatOpenAI(temperature=0)
class GradeDocuments(BaseModel):
    binary_score: str = Field(description="yes or no")  # Cevap: "yes" veya "no"
```

```python
structured_llm_grader = llm.with_structured_output(GradeDocuments)

system = """You are a grader assessing relevance of a document to a question.
Return 'yes' if relevant, 'no' otherwise."""
```

```python
grade_prompt = ChatPromptTemplate.from_messages([
    ("system", system),
    ("human", "Document: {document}\n\nQuestion: {question}")
])

retrieval_grader = grade_prompt | structured_llm_grader  # Zincir oluÅŸturulur
```

---

## ğŸš« 4. `hallucination_grader.py` â€“ Cevap HalÃ¼sinasyon mu?

### Ne Yapar?

- Cevap, gerÃ§ekten verilen belgelerle destekleniyor mu?
- Modelin uydurma yapÄ±p yapmadÄ±ÄŸÄ±nÄ± test eder.

### Kod ve AÃ§Ä±klama

```python
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.pydantic_v1 import BaseModel, Field
from langchain_core.runnables import RunnableSequence
from langchain_openai import ChatOpenAI
from dotenv import load_dotenv

load_dotenv()
```

```python
llm = ChatOpenAI(temperature=0)
class GradeHallucinations(BaseModel):
    binary_score: bool = Field(
        description="Answer is grounded in the facts, 'yes' or 'no'"
    )
```

```python
structured_llm_grader = llm.with_structured_output(GradeHallucinations)

system = """You are a grader assessing whether an answer is supported by given facts.
Return 'yes' or 'no'."""

hallucination_prompt = ChatPromptTemplate.from_messages([
    ("system", system),
    ("human", "Facts: {documents}\n\nAnswer: {generation}")
])

hallucination_grader = hallucination_prompt | structured_llm_grader
```

---

## ğŸ”€ 5. `router.py` â€“ Sorgu YÃ¶nlendirme

### Ne Yapar?

- Soru web'den mi cevaplanmalÄ± yoksa veri tabanÄ±ndan mÄ±?
- LLM'e yÃ¶nlendirme yaptÄ±rÄ±r: `"vectorstore"` veya `"websearch"`

### Kod ve AÃ§Ä±klama

```python
from typing import Literal
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.pydantic_v1 import BaseModel, Field
from langchain_openai import ChatOpenAI
from dotenv import load_dotenv

load_dotenv()
```

```python
class RouteQuery(BaseModel):
    datasource: Literal["vectorstore", "websearch"] = Field(
        ..., description="Choose to route to vectorstore or websearch."
    )
```

```python
llm = ChatOpenAI(temperature=0)
structured_llm_router = llm.with_structured_output(RouteQuery)

system = """You are an expert router.
Use 'vectorstore' for symbolic dream analysis. Use 'websearch' for all else."""

route_prompt = ChatPromptTemplate.from_messages([
    ("system", system),
    ("human", "{question}")
])

question_router = route_prompt | structured_llm_router
```

---

## ğŸ“¦ 6. `__init__.py` â€“ Zincirleri Paketleme

```python
from graph.chains.answer_grader import answer_grader
from graph.chains.generation import generation_chain
from graph.chains.retrieval_grader import retrieval_grader
from graph.chains.hallucination_grader import hallucination_grader
from graph.chains.router import question_router

__all__ = [
    "answer_grader",
    "generation_chain",
    "retrieval_grader",
    "hallucination_grader",
    "question_router"
]
```

> Bu dosya sayesinde zincirler dÄ±ÅŸarÄ±dan eriÅŸilebilir hale gelir.

